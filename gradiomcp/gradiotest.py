import asyncio
import gradio as gr
import openai
from dotenv import load_dotenv
from mcpclient import MCPOpenAIClient
load_dotenv("../.env")
client = openai.OpenAI()

def chat(user_input, history):
    history.append({"role": "user", "content": user_input})
    
    response = client.chat.completions.create(
            model="gpt-4.1-nano",
            messages=history
        )
    reply = response.choices[0].message.content
    history.append({"role": "assistant", "content": reply})

    # å±¥æ­´ã‚’ Markdown å½¢å¼ã§æ•´å½¢
    chat_log = ""
    for msg in history:
        if msg["role"] == "user":
            chat_log += f"**ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼:** {msg['content']}\n\n"
        elif msg["role"] == "assistant":
            chat_log += f"**ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ:** {msg['content']}\n\n"


    return "", reply, history, chat_log


def respond(user_input, history):
    _, bot_msg, updated_history, chat_log = chat(user_input, history)
    return "", bot_msg, updated_history, chat_log

with gr.Blocks() as demo:
    gr.Markdown("## ğŸ’¬ ç§ã®OpenAI ãƒãƒ£ãƒƒãƒˆ")

    with gr.Row():
        with gr.Column():
            user_text = gr.Textbox(label="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›", placeholder="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        with gr.Column():
            bot_response = gr.Textbox(label="LLMã®å¿œç­”", interactive=False)

    chat_history_display = gr.Markdown()
    state = gr.State([])

    user_text.submit(respond, [user_text, state], [user_text, bot_response, state,chat_history_display])

    demo.launch(share=True)
