import asyncio
import gradio as gr
import nest_asyncio
from mcpclient import MCPOpenAIClient

# nest_asyncioã‚’é©ç”¨ã—ã¦ãƒã‚¹ãƒˆã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’è¨±å¯ã™ã‚‹ï¼ˆJupyter/IPythonã§å¿…è¦ï¼‰
nest_asyncio.apply()

client = MCPOpenAIClient()

async def chat(user_input, history):
        
    reply = await client.process_query(user_input)

    history.append({"role": "assistant", "content": reply})

    # å±¥æ­´ã‚’ Markdown å½¢å¼ã§æ•´å½¢
    chat_log = ""
    for msg in history:
        if msg["role"] == "user":
            chat_log += f"**ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼:** {msg['content']}\n\n"
        elif msg["role"] == "assistant":
            chat_log += f"**ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ:** {msg['content']}\n\n"


    return "", reply, history, chat_log


async def respond(user_input, history):
    _, bot_msg, updated_history, chat_log = await chat(user_input, history)
    return "", bot_msg, updated_history, chat_log

async def main():
    await client.connect_to_server("server.py") #ok

    #gradio
    with gr.Blocks() as demo:
        gr.Markdown("## ğŸ’¬ ç§ã®OpenAI ãƒãƒ£ãƒƒãƒˆ")

        with gr.Row():
            with gr.Column():
                user_text = gr.Textbox(label="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›", placeholder="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            with gr.Column():
                bot_response = gr.Textbox(label="LLMã®å¿œç­”", interactive=False)

        chat_history_display = gr.Markdown()
        state = gr.State([])

        user_text.submit(respond, [user_text, state], [user_text, bot_response, state,chat_history_display])

        demo.launch(share=True)

    await client.cleanup()


if __name__ == "__main__":
    asyncio.run(main())


